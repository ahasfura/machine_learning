\documentclass{article}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{fullpage}

\begin{document}
\title{6.867: Homework 1}
\author{Andres Hasfura and Kathryn Evans}
\maketitle
\section{Gradient Descent}
Gradient descent works by updating an initial guess by taking a step opposite the direction of the gradient at that initial guess. Moving opposite the gradient helps  to effectively move "downhill" in terms of the function value.  The formulation of the gradient descent method is as follows
\begin{equation}
x(\tau+1) = x(\tau) - \alpha \nabla F(x(\tau))
\end{equation}

Where $ x(\tau)$ is the current guess, with $\tau$ being the current iteration, $\alpha$ is the step size and $F(x)$ is the function which will be evaluated. This method is carried out until there is convergence, which is checked by looking at the norm of successive guesses and seeing if it is less than the required tolerance, $\epsilon$,   



\begin{equation} 
\left \lVert x(\tau+1)-x(\tau) \right \rVert \leq \epsilon
\end{equation}







\end{document}