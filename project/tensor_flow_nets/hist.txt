[0.94140625, 0.9296875, 0.9375, 0.94140625, 0.9453125, 0.953125, 0.93359375, 0.94140625, 0.9375, 0.94921875, 0.9296875, 0.953125, 0.9453125, 0.92578125, 0.9453125, 0.9296875, 0.9296875, 0.9453125, 0.92578125, 0.92578125, 0.9375, 0.9375, 0.9375, 0.9296875, 0.94921875, 0.92578125, 0.93359375, 0.91796875, 0.93359375, 0.9375]
We implemented the multi-layer neural network and convolutional neural network and optimized them for varying parameters. The best test errors obtained on the networks we implemented were 6.2\% and 2.7\% for the multi-layer network and convolutional network respectively. We then replicated these networks using TensorFlow, compared our results with Lecun's results and did some further analysis to gain deeper insight.
 Using TensorFlow, we obtained our best result with a test error of merely 1.6\% using the network architecture that corresponds with LeNet-4. Considering that our best results were from deep networks and not from two-layer model, it is evident to us that deep neural networks are superior to the simple two-layer model. Deep neural networks are a powerful tool and it is no surprise that deep learning is increasing in popularity.